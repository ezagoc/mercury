{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4ea5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from tweetple import TweetPle\n",
    "sys.path.insert(0, '../../src/utils')\n",
    "from funcs import *\n",
    "from datetime import date, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../../src/utils')\n",
    "from general import *\n",
    "from scrape import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edf23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Retrieve Content Shared By Influencers During Treatment\n",
    "\n",
    "-- keywords: #FactsMatter, @AfricaCheck\n",
    "-- start date: 13-03-23\n",
    "-- end date:\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from tweetple import TweetPle\n",
    "sys.path.insert(0, '../../src/utils')\n",
    "from funcs import *\n",
    "from datetime import date, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../../src/utils')\n",
    "from general import *\n",
    "from scrape import *\n",
    "\n",
    "\n",
    "def start_date(days_ago):\n",
    "    \"\"\"Start date of scrape\"\"\"\n",
    "    start = str(date.today() - timedelta(days_ago))\n",
    "    start = start + \"T00:00:00Z\"\n",
    "\n",
    "    return start\n",
    "\n",
    "\n",
    "def end_date(days_ago):\n",
    "    \"\"\"Start date of scrape\"\"\"\n",
    "    end = str(date.today() - timedelta(days_ago))\n",
    "    end = end + \"T23:59:59Z\"\n",
    "\n",
    "    return end\n",
    "\n",
    "\n",
    "def scrape_tweets(accounts, path, bearer_token, days_ago):\n",
    "    \"\"\"Scrape Tweets\"\"\"\n",
    "    end = end_date(days_ago - 6)\n",
    "    TweetPle.TweetStreamer(\n",
    "        accounts, bearer_token, path, start_date(days_ago), end\n",
    "    ).main()\n",
    "\n",
    "    return print(\"Content scraped\")\n",
    "\n",
    "\n",
    "def get_paths(days_ago, country):\n",
    "\n",
    "    base = f\"../../data/03-experiment/{country}/treatment/influencers/\"\n",
    "    rest = timedelta(days_ago - 6)\n",
    "    datep = str(date.today() - rest)\n",
    "    path_tw = base + \"00-raw/twitter/\" + datep\n",
    "\n",
    "    return path_tw, base, datep\n",
    "\n",
    "\n",
    "def tweet_types(path_read):\n",
    "    df = read_files(path_read)\n",
    "    df.referenced_tweets = df.referenced_tweets.fillna({i: {} for i in df.index})\n",
    "    m = pd.DataFrame(df[\"referenced_tweets\"].tolist())\n",
    "    m = m[0].apply(pd.Series)\n",
    "    m.replace(\n",
    "        {\n",
    "            \"retweeted\": \"retweet\",\n",
    "            \"replied_to\": \"reply\",\n",
    "            \"quoted\": \"quote\",\n",
    "            np.nan: \"tweet\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    df[\"type\"] = m[\"type\"]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(\"referenced_tweets\", axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def content_twitter(path):\n",
    "    \"\"\"Find Tweets containing #FactsMatter\"\"\"\n",
    "    pattern = '|'.join([f'(?i){word}' for word in words_tweets])\n",
    "    pattern_url = '|'.join([f'(?i){url}' for url in urls_list])\n",
    "    # df = tweet_types(path)\n",
    "    df = read_files(path)\n",
    "    df = expand_column(df, \"entities.hashtags\")\n",
    "    df.rename({\"tag\": \"hashtag\"}, axis=1, inplace=1)\n",
    "    df = df.drop([\"end\", \"start\"], axis=1)\n",
    "    df = expand_column(df, \"entities.urls\")\n",
    "    df0 = df.loc[df[\"text\"].str.contains(\"#factsmatter\", case=False)]\n",
    "    df0['campaign_hashtag'] = 1\n",
    "    df1 = df.loc[df[\"text\"].str.contains(\"@africacheck\", case=False)]\n",
    "    df1['campaign_hashtag'] = 1\n",
    "    df2 = df.loc[df[\"text\"].str.contains(pattern, case=False)]\n",
    "    df2 = df2[~df2['id'].isin(list(list(df0.id)+list(df1.id)))]\n",
    "    df2['campaign_hashtag'] = 0\n",
    "    df3 = df.loc[df[\"expanded_url\"].str.contains(pattern_url, case=False, na=False)]\n",
    "    df3 = df3[~df3['id'].isin(list(list(df0.id)+list(df1.id)))]\n",
    "    df3['campaign_hashtag'] = 0\n",
    "    df = df0.append(df1).append(df2).append(df3).drop_duplicates(subset=\"id\").reset_index(drop=True)\n",
    "    try:\n",
    "        df[\"retweet\"] = np.where(df.url.isna(), 1, 0)\n",
    "    except:\n",
    "        df[\"url\"] = np.nan\n",
    "        df[\"retweet\"] = 1\n",
    "    df = df[df[\"retweet\"] != 1]\n",
    "    df = df.drop(\"retweet\", axis=1)\n",
    "    df[\"tweet_url\"] = \"https://twitter.com/\" + df.handle + \"/status/\" + df.id\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "def content_twitter_old(path):\n",
    "    \"\"\"Find Tweets containing #FactsMatter\"\"\"\n",
    "    # df = tweet_types(path)\n",
    "    df = read_files(path)\n",
    "    df = expand_column(df, \"entities.hashtags\")\n",
    "    df.rename({\"tag\": \"hashtag\"}, axis=1, inplace=1)\n",
    "    df = df.drop([\"end\", \"start\"], axis=1)\n",
    "    df0 = df.loc[df[\"text\"].str.contains(\"#factsmatter\", case=False)]\n",
    "    df1 = df.loc[df[\"text\"].str.contains(\"@africacheck\", case=False)]\n",
    "    df = df0.append(df1).drop_duplicates(subset=\"id\").reset_index(drop=True)\n",
    "    df = expand_column(df, \"entities.urls\")\n",
    "    try:\n",
    "        df[\"retweet\"] = np.where(df.url.isna(), 1, 0)\n",
    "    except:\n",
    "        df[\"url\"] = np.nan\n",
    "        df[\"retweet\"] = 1\n",
    "    df = df[df[\"retweet\"] != 1]\n",
    "    df = df.drop(\"retweet\", axis=1)\n",
    "    df[\"tweet_url\"] = \"https://twitter.com/\" + df.handle + \"/status/\" + df.id\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def incremental_range(start, stop, step, inc):\n",
    "    value = start\n",
    "    while value < stop:\n",
    "        yield value\n",
    "        value += step\n",
    "        step += inc\n",
    "\n",
    "\n",
    "def create_list(df, start, step, inc):\n",
    "    stop = len(df.columns)\n",
    "    a_list = list(incremental_range(start, stop, step, inc))\n",
    "\n",
    "    return a_list\n",
    "\n",
    "\n",
    "def create_dictionaries(contents, n_contents, a_list, name1, name2):\n",
    "    a_dict = dict(zip(contents, a_list))\n",
    "    b_dict = dict(zip(n_contents, a_list))\n",
    "    a_dict = {k: name1 + v for k, v in a_dict.items()}\n",
    "    b_dict = {k: name2 + v for k, v in b_dict.items()}\n",
    "\n",
    "    return a_dict, b_dict\n",
    "\n",
    "\n",
    "def rename_columns(df, a_dict, b_dict):\n",
    "    for key, value in a_dict.items():\n",
    "        df.columns.values[key] = value\n",
    "    for key, value in b_dict.items():\n",
    "        df.columns.values[key] = value\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicated_columns(df):\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def problematic(df, t_col, n_col, str_find):\n",
    "    prob = [col for col in df.columns if str_find in col]\n",
    "    df[\"auxiliar\"] = df[prob].sum(axis=1)\n",
    "    df[n_col] = np.where((df[\"auxiliar\"] == 0) & (df[t_col] == 1), 1, 0)\n",
    "    df = df.drop([\"auxiliar\"], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cd2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_parquet(\"/Users/joaquinbarrutia/Dropbox/Bolivia_Project/social-media-influencers-af/data/03-experiment/KE/treatment/influencers/00-raw/twitter/2023-05-07/2314837515.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db1bfbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '|'.join([f'(?i){word}' for word in words_tweets])\n",
    "pattern_url = '|'.join([f'(?i){url}' for url in urls_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "324c325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_files(\"/Users/joaquinbarrutia/Dropbox/Bolivia_Project/social-media-influencers-af/data/03-experiment/KE/treatment/influencers/00-raw/twitter/2023-05-07/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd652271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1654352219762827266</td>\n",
       "      <td>1654352219762827266</td>\n",
       "      <td>2023-05-05T05:08:00.000Z</td>\n",
       "      <td>Be wary of WhatsApp posts purporting Kenya's F...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653989106362269696</td>\n",
       "      <td>1653989106362269696</td>\n",
       "      <td>2023-05-04T05:05:07.000Z</td>\n",
       "      <td>RT @WIPO: The next chapter for the fashion ind...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653754353486897153</td>\n",
       "      <td>1653754353486897153</td>\n",
       "      <td>2023-05-03T13:32:17.000Z</td>\n",
       "      <td>RT @UN: A free press is essential for exposing...</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653754296578502722</td>\n",
       "      <td>1653754296578502722</td>\n",
       "      <td>2023-05-03T13:32:04.000Z</td>\n",
       "      <td>Happy Article 34 of The Constitution of Kenya ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653673874221834241</td>\n",
       "      <td>1653673874221834241</td>\n",
       "      <td>2023-05-03T08:12:30.000Z</td>\n",
       "      <td>RT @UN: Attacks on journalists are attacks on ...</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653673682391146496</td>\n",
       "      <td>1653673682391146496</td>\n",
       "      <td>2023-05-03T08:11:44.000Z</td>\n",
       "      <td>RT @WIPO: Can the sun☀️ help you with your hom...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653672375110492160</td>\n",
       "      <td>1653672375110492160</td>\n",
       "      <td>2023-05-03T08:06:32.000Z</td>\n",
       "      <td>RT @moneyacademyKE: Big win for consumers toda...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653672016698802181</td>\n",
       "      <td>1653672016698802181</td>\n",
       "      <td>2023-05-03T08:05:07.000Z</td>\n",
       "      <td>RT @salilsethi: Most businesses don't die beca...</td>\n",
       "      <td>4090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653266817631264771</td>\n",
       "      <td>1653266817631264771</td>\n",
       "      <td>2023-05-02T05:15:00.000Z</td>\n",
       "      <td>IT’S A SCAM! Use these straightforward steps t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>849395300</td>\n",
       "      <td>1653087464280539150</td>\n",
       "      <td>1653087464280539150</td>\n",
       "      <td>2023-05-01T17:22:19.000Z</td>\n",
       "      <td>RT @TheKSTS: The KSTS wishes all hardworking i...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id                   id      conversation_id  \\\n",
       "0  849395300  1654352219762827266  1654352219762827266   \n",
       "1  849395300  1653989106362269696  1653989106362269696   \n",
       "2  849395300  1653754353486897153  1653754353486897153   \n",
       "3  849395300  1653754296578502722  1653754296578502722   \n",
       "4  849395300  1653673874221834241  1653673874221834241   \n",
       "5  849395300  1653673682391146496  1653673682391146496   \n",
       "6  849395300  1653672375110492160  1653672375110492160   \n",
       "7  849395300  1653672016698802181  1653672016698802181   \n",
       "8  849395300  1653266817631264771  1653266817631264771   \n",
       "9  849395300  1653087464280539150  1653087464280539150   \n",
       "\n",
       "                 created_at  \\\n",
       "0  2023-05-05T05:08:00.000Z   \n",
       "1  2023-05-04T05:05:07.000Z   \n",
       "2  2023-05-03T13:32:17.000Z   \n",
       "3  2023-05-03T13:32:04.000Z   \n",
       "4  2023-05-03T08:12:30.000Z   \n",
       "5  2023-05-03T08:11:44.000Z   \n",
       "6  2023-05-03T08:06:32.000Z   \n",
       "7  2023-05-03T08:05:07.000Z   \n",
       "8  2023-05-02T05:15:00.000Z   \n",
       "9  2023-05-01T17:22:19.000Z   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  Be wary of WhatsApp posts purporting Kenya's F...            0.0   \n",
       "1  RT @WIPO: The next chapter for the fashion ind...           19.0   \n",
       "2  RT @UN: A free press is essential for exposing...          323.0   \n",
       "3  Happy Article 34 of The Constitution of Kenya ...            0.0   \n",
       "4  RT @UN: Attacks on journalists are attacks on ...          505.0   \n",
       "5  RT @WIPO: Can the sun☀️ help you with your hom...           16.0   \n",
       "6  RT @moneyacademyKE: Big win for consumers toda...          240.0   \n",
       "7  RT @salilsethi: Most businesses don't die beca...         4090.0   \n",
       "8  IT’S A SCAM! Use these straightforward steps t...            0.0   \n",
       "9  RT @TheKSTS: The KSTS wishes all hardworking i...            2.0   \n",
       "\n",
       "   reply_count  like_count  quote_count  impression_count  \n",
       "0          0.0         1.0          0.0              74.0  \n",
       "1          0.0         0.0          0.0               0.0  \n",
       "2          0.0         0.0          0.0               0.0  \n",
       "3          0.0         1.0          0.0              63.0  \n",
       "4          0.0         0.0          0.0               0.0  \n",
       "5          0.0         0.0          0.0               0.0  \n",
       "6          0.0         0.0          0.0               0.0  \n",
       "7          0.0         0.0          0.0               0.0  \n",
       "8          0.0         1.0          0.0              70.0  \n",
       "9          0.0         0.0          0.0               0.0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author_id']=='849395300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba67d315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quoted</th>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replied_to</th>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "      <td>2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweeted</th>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "      <td>4133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_id    id  conversation_id  created_at  text  retweet_count  \\\n",
       "type                                                                            \n",
       "quoted            712   712              712         712   712            712   \n",
       "replied_to       2109  2109             2109        2109  2109           2109   \n",
       "retweeted        4133  4133             4133        4133  4133           4133   \n",
       "\n",
       "            reply_count  like_count  quote_count  impression_count  \n",
       "type                                                                \n",
       "quoted              712         712          712               712  \n",
       "replied_to         2109        2109         2109              2109  \n",
       "retweeted          4133        4133         4133              4133  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['type']).count().tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64fc7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_twitter(path):\n",
    "    \"\"\"Find Tweets containing #FactsMatter\"\"\"\n",
    "    pattern = '|'.join([f'(?i){word}' for word in words_tweets])\n",
    "    pattern_url = '|'.join([f'(?i){url}' for url in urls_list])\n",
    "    # df = tweet_types(path)\n",
    "    df = read_files(path)\n",
    "    df = df[~df['text'].isnull()]\n",
    "    #df = expand_column(df, \"entities.hashtags\")\n",
    "    #df.rename({\"tag\": \"hashtag\"}, axis=1, inplace=1)\n",
    "    #df = df.drop([\"end\", \"start\"], axis=1)\n",
    "    #df = expand_column(df, \"entities.urls\")\n",
    "    df0 = df.loc[df[\"text\"].str.contains(\"#factsmatter\", case=False)]\n",
    "    df0['campaign_hashtag'] = 1\n",
    "    df1 = df.loc[df[\"text\"].str.contains(\"@africacheck\", case=False)]\n",
    "    df1['campaign_hashtag'] = 1\n",
    "    df2 = df.loc[df[\"text\"].str.contains(pattern, case=False)]\n",
    "    df2 = df2[~df2['id'].isin(list(list(df0.id)+list(df1.id)))]\n",
    "    df2['campaign_hashtag'] = 0\n",
    "    #df3 = df.loc[df[\"expanded_url\"].str.contains(pattern_url, case=False, na=False)]\n",
    "    #df3 = df3[~df3['id'].isin(list(list(df0.id)+list(df1.id)))]\n",
    "    #df3['campaign_hashtag'] = 0\n",
    "    df = df0.append(df1).append(df2).drop_duplicates(subset=\"id\").reset_index(drop=True)\n",
    "    #df = df[df['type']!='retweeted']\n",
    "    #try:\n",
    "     #   df[\"retweet\"] = np.where(df.url.isna(), 1, 0)\n",
    "    #except:\n",
    "     #   df[\"url\"] = np.nan\n",
    "      #  df[\"retweet\"] = 1\n",
    "    #df = df[df[\"retweet\"] != 1]\n",
    "    #df = df.drop(\"retweet\", axis=1)\n",
    "    #df[\"tweet_url\"] = \"https://twitter.com/\" + df.handle + \"/status/\" + df.id\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "343d0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_twitter(path):\n",
    "    \"\"\"Find Tweets containing #FactsMatter\"\"\"\n",
    "    pattern = '|'.join([f'(?i){word}' for word in words_tweets])\n",
    "    pattern_url = '|'.join([f'(?i){url}' for url in urls_list])\n",
    "    # df = tweet_types(path)\n",
    "    df = read_files(path)\n",
    "    df = df[~df['text'].isnull()]\n",
    "    #df = expand_column(df, \"entities.hashtags\")\n",
    "    #df.rename({\"tag\": \"hashtag\"}, axis=1, inplace=1)\n",
    "    #df = df.drop([\"end\", \"start\"], axis=1)\n",
    "    #df = expand_column(df, \"entities.urls\")\n",
    "    df0 = df.loc[df[\"text\"].str.contains(\"#factsmatter\", case=False)]\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4fe11ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-119-64fac4f38c2b>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df0['campaign_hashtag'] = 1\n",
      "<ipython-input-119-64fac4f38c2b>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['campaign_hashtag'] = 1\n",
      "<ipython-input-119-64fac4f38c2b>:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df0.append(df1).append(df2).drop_duplicates(subset=\"id\").reset_index(drop=True)\n",
      "<ipython-input-119-64fac4f38c2b>:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df0.append(df1).append(df2).drop_duplicates(subset=\"id\").reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df_tw = content_twitter(f\"/Users/joaquinbarrutia/Dropbox/Bolivia_Project/social-media-influencers-af/data/03-experiment/SA/treatment/influencers/00-raw/twitter/2023-05-07/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "947f6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6cf28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Client = tweepy.Client(bearer_token=bearer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Client.search_all_tweets(query = 'from:1653300807779975171', start_tweets = start, end_tweets = end, max_results=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a12d70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(data=None, includes={}, errors=[], meta={'result_count': 0})\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import tweepy\n",
    "import os\n",
    "\n",
    "client = tweepy.Client(bearer_token=bearer, wait_on_rate_limit=True)\n",
    "\n",
    "query = 'from:1653300807779975171'\n",
    "\n",
    "for response in tweepy.Paginator(client.search_all_tweets, query=query, start_time = start, end_time = end, max_results=500):\n",
    "    sleep(1)\n",
    "    print(response)\n",
    "    r = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "759c2e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "paginator = tweepy.Paginator(\n",
    "    client.search_all_tweets,               # The method you want to use\n",
    "    query=\"from:44196397\",                            # Some argument for this method\n",
    "    end_time=end,       # Some argument for this method   \n",
    "    start_time=start,     # Some argument for this method\n",
    "    max_results=500                        # How many tweets asked per request\n",
    ")\n",
    "\n",
    "try: \n",
    "    for page in paginator:      # Default to inf\n",
    "        print(page)\n",
    "        print(page.data)                       # The tweets are here\n",
    "        print(page.meta)                       # The count etc. are here\n",
    "        print(page.includes)  \n",
    "except tweepy.RateLimitError as exc:\n",
    "    print('Rate limit!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ad2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start =  '2023-05-01T00:00:00Z'\n",
    "end = '2023-05-07T00:00:00Z'\n",
    "bearer = \"AAAAAAAAAAAAAAAAAAAAAFpgZAEAAAAAbJS59UWzipi32ixd7LHtXov9olo%3D7gxD8Afshgj4munMXHLU08jzRdTpsAh4RZqq7VBofq1wAvkx1T\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10283a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b1c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l_/pc12z1g16z359gcfw1jgy3d00000gn/T/ipykernel_14734/805142309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTweetPle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1126820633244065792'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbearer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/joaquinbarrutia/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tweetple/TweetPle.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;31m# list of tweet ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer_tweetids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mvalidators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tweetple/TweetPle.py\u001b[0m in \u001b[0;36mstreamer_tweetids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetStatsFromTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbearer_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             df_stats = df_stats.append(\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tweetple/TwitterFullArchive.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbearer_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_consulted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "TweetPle.TweetStreamer('1126820633244065792', bearer, '/Users/joaquinbarrutia/',start, end ).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f89caff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>503359879</td>\n",
       "      <td>1655129258350575616</td>\n",
       "      <td>1655127830311899136</td>\n",
       "      <td>2023-05-07T08:35:40.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@TheMiddleBorn @wwwasike</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246769503</td>\n",
       "      <td>1655255265510318082</td>\n",
       "      <td>1655163955956920320</td>\n",
       "      <td>2023-05-07T16:56:23.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@DM_holdings Has nothing to do with the econom...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16435650</td>\n",
       "      <td>1654186791040106498</td>\n",
       "      <td>1654157750560079873</td>\n",
       "      <td>2023-05-04T18:10:38.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@imbuyuz The proposed increase looks like one ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270834723</td>\n",
       "      <td>1652995999634161666</td>\n",
       "      <td>1652995999634161666</td>\n",
       "      <td>2023-05-01T11:18:52.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>We celebrate you #TeamPR. Happy Labour Day. ht...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58806221</td>\n",
       "      <td>1654728520164057089</td>\n",
       "      <td>1654728520164057089</td>\n",
       "      <td>2023-05-06T06:03:17.000Z</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>RT @SemaUkweliKenya: David Sadera Munyakei: Po...</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4895104294</td>\n",
       "      <td>1653637345764159489</td>\n",
       "      <td>1653637345764159489</td>\n",
       "      <td>2023-05-03T05:47:20.000Z</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>RT @UNCCD: Meet our Goodwill Ambassador @baaba...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17700414</td>\n",
       "      <td>1654435834894905346</td>\n",
       "      <td>1654434054186442752</td>\n",
       "      <td>2023-05-05T10:40:15.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@deeRsquared Amepeleka detectives wa Assmio</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291061156</td>\n",
       "      <td>1655309552311476226</td>\n",
       "      <td>1655309145870876672</td>\n",
       "      <td>2023-05-07T20:32:06.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>Tiwa Savage stunning at the #CoronationConcert...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2497334080</td>\n",
       "      <td>1655266931375501312</td>\n",
       "      <td>1655265090856267779</td>\n",
       "      <td>2023-05-07T17:42:44.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@berylsavanah We try again next Sunday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2314837515</td>\n",
       "      <td>1655051017921212418</td>\n",
       "      <td>1655036014719557632</td>\n",
       "      <td>2023-05-07T03:24:46.000Z</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>@RadioCitizenFM Amongura Teso nabarikiwa #Pamb...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author_id                   id      conversation_id  \\\n",
       "0    503359879  1655129258350575616  1655127830311899136   \n",
       "0    246769503  1655255265510318082  1655163955956920320   \n",
       "0     16435650  1654186791040106498  1654157750560079873   \n",
       "0    270834723  1652995999634161666  1652995999634161666   \n",
       "0     58806221  1654728520164057089  1654728520164057089   \n",
       "..         ...                  ...                  ...   \n",
       "0   4895104294  1653637345764159489  1653637345764159489   \n",
       "0     17700414  1654435834894905346  1654434054186442752   \n",
       "0   1291061156  1655309552311476226  1655309145870876672   \n",
       "0   2497334080  1655266931375501312  1655265090856267779   \n",
       "0   2314837515  1655051017921212418  1655036014719557632   \n",
       "\n",
       "                  created_at        type  \\\n",
       "0   2023-05-07T08:35:40.000Z  replied_to   \n",
       "0   2023-05-07T16:56:23.000Z  replied_to   \n",
       "0   2023-05-04T18:10:38.000Z  replied_to   \n",
       "0   2023-05-01T11:18:52.000Z        None   \n",
       "0   2023-05-06T06:03:17.000Z   retweeted   \n",
       "..                       ...         ...   \n",
       "0   2023-05-03T05:47:20.000Z   retweeted   \n",
       "0   2023-05-05T10:40:15.000Z  replied_to   \n",
       "0   2023-05-07T20:32:06.000Z  replied_to   \n",
       "0   2023-05-07T17:42:44.000Z  replied_to   \n",
       "0   2023-05-07T03:24:46.000Z  replied_to   \n",
       "\n",
       "                                                 text  retweet_count  \\\n",
       "0                            @TheMiddleBorn @wwwasike            0.0   \n",
       "0   @DM_holdings Has nothing to do with the econom...            0.0   \n",
       "0   @imbuyuz The proposed increase looks like one ...            0.0   \n",
       "0   We celebrate you #TeamPR. Happy Labour Day. ht...            5.0   \n",
       "0   RT @SemaUkweliKenya: David Sadera Munyakei: Po...          435.0   \n",
       "..                                                ...            ...   \n",
       "0   RT @UNCCD: Meet our Goodwill Ambassador @baaba...           21.0   \n",
       "0         @deeRsquared Amepeleka detectives wa Assmio            0.0   \n",
       "0   Tiwa Savage stunning at the #CoronationConcert...            0.0   \n",
       "0              @berylsavanah We try again next Sunday            0.0   \n",
       "0   @RadioCitizenFM Amongura Teso nabarikiwa #Pamb...            0.0   \n",
       "\n",
       "    reply_count  like_count  quote_count  impression_count  \n",
       "0           1.0        22.0          0.0              45.0  \n",
       "0           0.0         3.0          0.0             245.0  \n",
       "0           0.0         1.0          0.0              13.0  \n",
       "0           0.0        20.0          0.0            1109.0  \n",
       "0           0.0         0.0          0.0               0.0  \n",
       "..          ...         ...          ...               ...  \n",
       "0           0.0         0.0          0.0               0.0  \n",
       "0           0.0         0.0          0.0              27.0  \n",
       "0           0.0         5.0          0.0            1055.0  \n",
       "0           0.0         1.0          0.0               6.0  \n",
       "0           0.0         0.0          0.0               1.0  \n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be0bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>impression_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [author_id, id, conversation_id, created_at, type, text, retweet_count, reply_count, like_count, quote_count, impression_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author_id']==1126820633244065792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1386f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def africa_report(path_read, datep):\n",
    "    \"\"\"Generate report for AfricaCheck\"\"\"\n",
    "    base = path_read.split(\"/*/\")[0]\n",
    "    df = pd.concat(map(pd.read_excel, glob.glob(f\"{path_read}/twitter.xlsx\")), axis=1)\n",
    "    contents = create_list(df, 5, 7, 0)\n",
    "    n_contents = create_list(df, 6, 7, 0)\n",
    "    stop = len(df.columns)\n",
    "    weeks = list(map(str, range(1, int(stop / 7) + 1)))\n",
    "    n_contents_dict, contents_dict = create_dictionaries(\n",
    "        contents, n_contents, weeks, \"content_w\", \"n_content_w\"\n",
    "    )\n",
    "    df = rename_columns(df, contents_dict, n_contents_dict)\n",
    "    df = drop_duplicated_columns(df)\n",
    "    df = problematic(df, \"treatment\", \"potentially_problematic\", \"content_w\")\n",
    "    df.to_excel(f\"{base}/{datep}/tracker_twitter.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# def monitor_influencers(days_ago=1):\n",
    "# --35, 28, 21, 14\n",
    "def monitor_influencers(days_ago=7, country='KE'):\n",
    "    \"\"\"Run process\"\"\"\n",
    "    # Twitter\n",
    "    _, _, _, bearer_token, _, _,_ = twitter_credentials(\n",
    "        \"../../conf/credentials.yaml\"\n",
    "    )\n",
    "    participants_tw = get_participants_twitter(country)\n",
    "    usernames_tw = list(participants_tw[\"username\"])\n",
    "    path_tw, base, datep = get_paths(days_ago, country)\n",
    "    create_folder(path_tw)\n",
    "    scrape_tweets(usernames_tw, f\"{path_tw}/\", bearer_token, days_ago)\n",
    "    df_tw = content_twitter(f\"{path_tw}\")\n",
    "    create_folder(f\"{base}01-preprocessed/content/{datep}\")\n",
    "    df_tw.to_excel(f\"{base}01-preprocessed/content/{datep}/tweets.xlsx\", index=False)\n",
    "    count_tw = df_tw.groupby(\"handle\").count()\n",
    "    count_tw_2 = df_tw.groupby(\"handle\").sum()\n",
    "    count_tw = count_tw.reset_index()[[\"handle\", \"id\"]]\n",
    "    count_tw_2 = count_tw_2.reset_index()[[\"handle\",'public_metrics.impression_count',\n",
    "                                       'public_metrics.like_count', 'public_metrics.quote_count',\n",
    "                                       'public_metrics.reply_count', 'public_metrics.retweet_count']]\n",
    "    count_tw = count_tw.rename({\"id\": \"n_content\", \"handle\": \"username\",\n",
    "                                'public_metrics.impression_count': \"n_impressions\",\n",
    "                                'public_metrics.like_count':'n_likes', 'public_metrics.quote_count':'n_quotes',\n",
    "                                'public_metrics.reply_count':'n_replies', 'public_metrics.retweet_count':'n_retweets'}, axis=1)\n",
    "    count_tw_2 = count_tw_2.rename({\"handle\": \"username\",\n",
    "                                'public_metrics.impression_count': \"n_impressions\",\n",
    "                                'public_metrics.like_count':'n_likes', 'public_metrics.quote_count':'n_quotes',\n",
    "                                'public_metrics.reply_count':'n_replies', 'public_metrics.retweet_count':'n_retweets'}, axis=1)\n",
    "    count_tw = count_tw.merge(count_tw_2, how=\"left\", on=\"username\")\n",
    "    found = list(df_tw.handle.unique())\n",
    "    participants_tw[\"content\"] = np.where(participants_tw[\"username\"].isin(found), 1, 0)\n",
    "    create_folder(f\"{base}01-preprocessed/report/{datep}\")\n",
    "    participants_tw = participants_tw.merge(count_tw, how=\"left\", on=\"username\")\n",
    "    participants_tw[[\"n_content\",\"n_impressions\", \n",
    "                 \"n_likes\",\"n_quotes\", \"n_replies\", \n",
    "                 \"n_retweets\"]] = participants_tw[[\"n_content\",\"n_impressions\", \n",
    "                                                  \"n_likes\",\"n_quotes\",\n",
    "                                                  \"n_replies\", \"n_retweets\"]].fillna(0)\n",
    "    participants_tw.to_excel(\n",
    "        f\"{base}01-preprocessed/report/{datep}/twitter.xlsx\", index=False\n",
    "    )\n",
    "    summ_tw = participants_tw.groupby([\"treatment\"]).sum().reset_index()\n",
    "    summ_tw = summ_tw[[\"treatment\", \"content\"]]\n",
    "    summ_tw = summ_tw.rename({\"content\": \"percent_share\"}, axis=1)\n",
    "    summ_tw[\"percent_share\"] = (summ_tw[\"percent_share\"] / 38) * 100\n",
    "    summ_tw.to_excel(\n",
    "        f\"{base}01-preprocessed/report/{datep}/summary_twitter.xlsx\", index=False\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    monitor_influencers()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
