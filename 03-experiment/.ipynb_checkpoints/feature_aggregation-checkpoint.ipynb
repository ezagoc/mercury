{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category = FutureWarning)\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_path(country, week = 'march'):\n",
    "    base = f'../../data/03-experiment/{country}/'\n",
    "    path_tw = base + f'treatment/followers/00-raw/tweets/{week}/'\n",
    "    rand = f'../../data/02-randomize/{country}/04-stratification/integrate/followers_randomized.parquet'\n",
    "    baseline = base + 'baseline/00-raw/followers/tweets/'\n",
    "    agg = base + f'treatment/followers/01-preprocess/'\n",
    "    agg_base = base + 'baseline/01-preprocess/followers/'\n",
    "    return path_tw, base, rand, baseline, agg, agg_base\n",
    "\n",
    "def summ_followers(df):\n",
    "    metrics = [col for col in df.columns if 'total_' in col]\n",
    "    cols = metrics + ['verifiability', 'true']\n",
    "\n",
    "    df_agg = df[['handle', 'author_id'] + \n",
    "        cols].groupby(['handle', 'author_id']).sum().reset_index()\n",
    "\n",
    "    df_mean = df[['handle', 'author_id'] + \n",
    "        cols].groupby(['handle', 'author_id']).mean().reset_index()\n",
    "    df_mean.rename(columns = \n",
    "        {col: col + '_mean' for col in df_mean.columns if col in cols}, \n",
    "        inplace=True)\n",
    "\n",
    "    df_count = df[['handle', 'author_id']].groupby(['author_id']).count()\n",
    "    df_count.rename({'handle': 'n_posts'}, axis=1, inplace=True)\n",
    "\n",
    "    df_agg = df_agg.merge(df_mean, on=['handle', 'author_id'], how='left')\n",
    "    df_agg = df_agg.merge(df_count, on=['author_id'], how='left')\n",
    "\n",
    "    return df_agg\n",
    "\n",
    "\n",
    "def summ_followers2(df):\n",
    "    metrics = [col for col in df.columns if 'total_' in col]\n",
    "    cols = metrics + ['verifiability', 'true']\n",
    "\n",
    "    df_agg = df[['handle', 'author_id'] + \n",
    "        cols].groupby(['handle', 'author_id']).sum().reset_index()\n",
    "\n",
    "    df_count = df[['handle', 'author_id']].groupby(['author_id']).count()\n",
    "    df_count.rename({'handle': 'n_posts'}, axis=1, inplace=True)\n",
    "\n",
    "    df_agg = df_agg.merge(df_count, on=['author_id'], how='left')\n",
    "\n",
    "    return df_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KENYA BASELINE:\n",
    "path_tw, base, rand, baseline, agg, agg_base = get_path('KE', 'march')\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "for i in range(0, 84):\n",
    "    df = pd.read_parquet(f'{agg_base}predicted/baseline_{i}.parquet.gzip')\n",
    "    df_agg = summ_followers(df)\n",
    "    df_final = pd.concat([df_final, df_agg])\n",
    "\n",
    "df_final = df_final.drop_duplicates(['handle']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['true'] = np.where(df_final['verifiability'] == 0, np.nan, df_final['true'])\n",
    "df_final.to_parquet(f'{agg_base}aggregated/baseline.parquet.gzip',\n",
    "        compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:54<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# SA BASELINE:\n",
    "path_tw, base, rand, baseline, agg, agg_base = get_path('SA', 'march')\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "for i in tqdm(range(0, 74)):\n",
    "    df = pd.read_parquet(f'{agg_base}predicted/baseline_{i}.parquet.gzip')\n",
    "    df_agg = summ_followers(df)\n",
    "    df_final = pd.concat([df_final, df_agg])\n",
    "\n",
    "df_final = df_final.drop_duplicates(['handle']).reset_index(drop=True)\n",
    "df_final['true'] = np.where(df_final['verifiability'] == 0, np.nan, df_final['true'])\n",
    "df_final.to_parquet(f'{agg_base}aggregated/baseline.parquet.gzip',\n",
    "        compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [02:06<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "### Separating posts from RTs\n",
    "country = 'SA'\n",
    "path_tw, base, rand, baseline, agg, agg_base = get_path(country, 'march')\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "# for i in tqdm(range(0, 84)): #KE\n",
    "for i in tqdm(range(0, 74)): #SA\n",
    "    df = pd.read_parquet(f'{agg_base}predicted/baseline_{i}.parquet.gzip')\n",
    "    df_final = pd.concat([df_final, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.reset_index(drop = True)\n",
    "\n",
    "df_RT = df_final[(df_final['text'].str.contains('RT @', case=True, regex=False)) & \n",
    "                 (df_final['total_comments'] == 0)]\n",
    "df_RT = df_RT.reset_index(drop=True)\n",
    "\n",
    "df_no_rt = df_final[(~df_final['text'].str.contains('RT @', \n",
    "                    case=True, regex=False)) | \n",
    "                    (df_final['total_comments'] > 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_RT) + len(df_no_rt) == len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rt_agg = summ_followers2(df_RT).reset_index(drop=True)\n",
    "df_no_rt_agg = summ_followers2(df_no_rt).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_rt_agg.columns if 'total_' in col] + ['verifiability', 'true', 'n_posts']\n",
    "df_rt_agg.rename(columns = \n",
    "        {col: col + '_rt_base' for col in df_rt_agg.columns if col in cols}, \n",
    "        inplace=True)\n",
    "\n",
    "df_no_rt_agg.rename(columns = \n",
    "        {col: col + '_no_rt_base' for col in df_no_rt_agg.columns if col in cols}, \n",
    "        inplace=True)\n",
    "\n",
    "df_rt_agg.rename(columns = {'handle': 'username', \n",
    "                       'author_id':'follower_id'}, inplace = True)\n",
    "df_no_rt_agg.rename(columns = {'handle': 'username', \n",
    "                       'author_id':'follower_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44201 entries, 0 to 44200\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   username            44201 non-null  object \n",
      " 1   follower_id         44201 non-null  object \n",
      " 2   ads_treatment       44201 non-null  float64\n",
      " 3   strat_block1        44201 non-null  object \n",
      " 4   strat_block2        44201 non-null  object \n",
      " 5   c_t_strong_total    44201 non-null  int32  \n",
      " 6   c_t_weak_total      44201 non-null  int32  \n",
      " 7   c_t_neither_total   44201 non-null  int32  \n",
      " 8   t_strong            44201 non-null  float64\n",
      " 9   t_weak              44201 non-null  float64\n",
      " 10  t_neither           44201 non-null  float64\n",
      " 11  shares_base         36800 non-null  float64\n",
      " 12  reactions_base      36800 non-null  float64\n",
      " 13  comments_base       36800 non-null  float64\n",
      " 14  verifiability_base  36800 non-null  float64\n",
      " 15  n_posts_base        44201 non-null  float64\n",
      " 16  true_base           29397 non-null  float64\n",
      " 17  bot_account         44201 non-null  int32  \n",
      "dtypes: float64(10), int32(4), object(4)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "## Merginig with Treatment data set:\n",
    "base = pd.read_parquet(f'../../data/04-analysis/{country}/baseline_features.parquet')\n",
    "filter = pd.read_parquet(f'../../data/04-analysis/{country}/baseline_features_filter.parquet')\n",
    "\n",
    "base = base[['username', 'follower_id', 'ads_treatment', \n",
    "             'strat_block1', 'strat_block2', 'c_t_strong_total', \n",
    "             'c_t_weak_total', 'c_t_neither_total', 't_strong',\n",
    "             't_weak', 't_neither', 'total_shares_sum',\n",
    "             'total_reactions_sum', 'total_comments_sum', \n",
    "             'verifiability_base', 'n_posts_base', 'true_base']]\n",
    "\n",
    "base.rename(columns = {'total_reactions_sum': 'reactions_base', \n",
    "                       'total_shares_sum':'shares_base', \n",
    "                       'total_comments_sum': 'comments_base'}, inplace = True)\n",
    "\n",
    "filter = filter[['username', 'follower_id', 'n_posts_base']]\n",
    "\n",
    "filter['bot_account'] = np.where(filter['n_posts_base'].isnull(), 1, 0)\n",
    "\n",
    "filter = filter[['follower_id', 'bot_account']]\n",
    "\n",
    "base = base.merge(filter, on = 'follower_id', how = 'left')\n",
    "\n",
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "base = base.merge(df_rt_agg, on=['follower_id', 'username'], \n",
    "                  how='left')\n",
    "\n",
    "base = base.merge(df_no_rt_agg, on=['follower_id', 'username'], \n",
    "                  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_base = [col for col in base.columns if '_base' in col]\n",
    "for x in cols_base:\n",
    "    base[x] = np.where(base[x].isnull(), 0, base[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_parquet(f'../../data/04-analysis/{country}/baseline_rt.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
