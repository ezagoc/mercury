{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d74ace-61f4-43bd-ac18-af7835ad994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tweetple import TweetPle\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import requests\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031f27b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tweetple import TweetPle\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "\n",
    "bearer_1 = 'AAAAAAAAAAAAAAAAAAAAAKzClQEAAAAAiPTKroWBwDBgemt7kOC2cjh45GY%3DnHQ4aOfnY1mAhPY0Y40JQ9FjbO1Gwit2eh68u2tDTBYkACzkCF'\n",
    "bearer_2 = 'AAAAAAAAAAAAAAAAAAAAAAB8lgEAAAAAtHuFxjMbRwl7WNHEOpMvzf7%2BGrc%3DATF52dZ90jRf9u9qxVvuiC7WLYCte5c9U4HrWfsuz9RK59Girq'\n",
    "bearer_3 = 'AAAAAAAAAAAAAAAAAAAAADBllgEAAAAApipe6qOeDEIfw%2FTMfc2xW89ebl4%3DxNO1rdxbIui1egv8O2fHEFmFmFHykxraQyCeqfaa7vV3plAjI6'\n",
    "bearer_4 = 'AAAAAAAAAAAAAAAAAAAAAGfelQEAAAAAJnIyk0mYMHkSLSzjgcJPY9NdPgw%3D6RhIOrBneg0CHnqUoxTLrZGejUyVJm9AFFzvN44dLiRz35kBpp'\n",
    "\n",
    "country = 'KE'\n",
    "def get_path(country):\n",
    "    base = f'../../data/01-characterize/followers/{country}/'\n",
    "    path_save_c = base + '00-raw/collect/'\n",
    "    path_save_i = base + '00-raw/integrate/'\n",
    "\n",
    "    return path_save_c, path_save_i\n",
    "\n",
    "path_save_c, path_save_i = get_path(country)\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = path_save_c\n",
    "path_s = f'../../data/03-experiment/{country}/baseline/00-raw/influencers/tweets/'\n",
    "# Run R Script get_users_info() to get the ids, import them:\n",
    "df = pd.read_excel(f'../../data/01-characterize/influencers/{country}/file_AfricaCheck.xlsx')\n",
    "ids_final = list(df['handle'].astype(str))\n",
    "\n",
    "mypath = path_s\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles = [f.replace('.parquet', '') for f in onlyfiles]\n",
    "#ids de tweets\n",
    "#ids_tweets = list(df.id)\n",
    "ids = list(set(ids_final).difference(onlyfiles))\n",
    "ids.sort()\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c65a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bearer Token de Academic Twitter API\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAAnSPwEAAAAAemlHrPxPMRFZr592mS0iblQvxmQ%3D5rdloTu8HByQAC2h2qT3LJcvZ3ZVhGUS5OVubGnPAVlJIcVkTE\"\n",
    "\n",
    "## BASELINE DATES\n",
    "### 6 months\n",
    "start =  '2022-07-08T00:00:00Z'\n",
    "end = '2022-07-10T00:00:00Z'\n",
    "\n",
    "#TweetPle.TweetStreamer([\"j_barrutia\"], bearer_token, path_save = \"/Users/joaquinbarrutia/Downloads/\", start_time = start, end_time = end).main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4431d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09T06:06:55.000Z: https://t.co/MpOFP2bdFU https://t.co/On0uohYzSh\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace with your own Bearer Token\n",
    "BEARER_TOKEN = bearer_token\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "    return headers\n",
    "\n",
    "def get_tweets(username, start_time, end_time):\n",
    "    search_url = f\"https://api.twitter.com/2/tweets/search/all\"\n",
    "    query_params = {\n",
    "        'query': f'from:{username}',\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'max_results': 100,  # maximum results per request (can be adjusted)\n",
    "        'tweet.fields': 'created_at,text'\n",
    "    }\n",
    "\n",
    "    headers = create_headers(BEARER_TOKEN)\n",
    "    response = requests.get(search_url, headers=headers, params=query_params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def format_date(date):\n",
    "    return date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Define the username and date range\n",
    "username = 'j_barrutia'\n",
    "start_date = datetime(2022, 6, 8)\n",
    "end_date = datetime(2022, 6, 10)\n",
    "\n",
    "start_time = format_date(start_date)\n",
    "end_time = format_date(end_date)\n",
    "\n",
    "# Fetch the tweets\n",
    "tweets_data = get_tweets(username, start_time, end_time)\n",
    "\n",
    "# Print the tweets\n",
    "if 'data' in tweets_data:\n",
    "    for tweet in tweets_data['data']:\n",
    "        print(f\"{tweet['created_at']}: {tweet['text']}\")\n",
    "else:\n",
    "    print(\"No tweets found.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
