{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8d6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_path(country):\n",
    "    path_pilot = f'../../../social-media-influencers-africa/data/04-analysis/{country}/'\n",
    "    path_batches = f'../../data/04-analysis/{country}/'\n",
    "    return path_pilot, path_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0330a3",
   "metadata": {},
   "source": [
    "### Aggregating ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e1b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch1 and Batch2\n",
    "for country in ['KE', 'SA']:\n",
    "    path_pilot, path_batches = get_path(country)\n",
    "    for i in range(0, 4):\n",
    "        tie1 = pd.read_parquet(f'{path_batches}ties{i}.parquet')\n",
    "        tie1['batch_id'] = 'b1'\n",
    "        tie2 = pd.read_parquet(f'{path_batches}ties_batch2_{i}.parquet')\n",
    "        tie2['batch_id'] = 'b2'\n",
    "        \n",
    "        tie = pd.concat([tie1, tie2]).reset_index(drop = True)\n",
    "        tie.to_parquet(f'{path_batches}ties_batch1_batch2_{i}.parquet', \n",
    "                       index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0242bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pilot, path_batches = get_path('KE')\n",
    "tie_prueba = pd.read_parquet(f'{path_pilot}filtered_ties.parquet')\n",
    "tie_prueba['batch_id'] = 'p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0926cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "    tie1 = pd.read_parquet(f'{path_batches}ties_batch1_batch2_{i}.parquet')\n",
    "    tie2 = tie_prueba[[col for col in tie1.columns]]\n",
    "    \n",
    "    tie = pd.concat([tie1, tie2]).reset_index(drop = True)\n",
    "    tie.to_parquet(f'{path_batches}ties_batch1_batch2_p_{i}.parquet', \n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d5661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2692\\1869152705.py:10: FutureWarning: Passing 'suffixes' which cause duplicate columns {'__index_level_0___x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  tie_prueba = tie_prueba.merge(tie_3, on = 'follower_id', how = 'left')\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2692\\1869152705.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tie_prueba['batch_id'] = 'p'\n"
     ]
    }
   ],
   "source": [
    "path_pilot, path_batches = get_path('SA')\n",
    "tie_0 = pd.read_parquet(f'{path_pilot}filtered_ties0.parquet').reset_index(drop=True)\n",
    "tie_1 = pd.read_parquet(f'{path_pilot}filtered_ties1.parquet').reset_index(drop=True)\n",
    "tie_2 = pd.read_parquet(f'{path_pilot}filtered_ties2.parquet').reset_index(drop=True)\n",
    "tie_3 = pd.read_parquet(f'{path_pilot}filtered_ties3.parquet').reset_index(drop=True)\n",
    "tie_4 = pd.read_parquet(f'{path_pilot}filtered_ties4.parquet').reset_index(drop=True)\n",
    "\n",
    "tie_prueba = tie_0.merge(tie_1, on = 'follower_id', how = 'left')\n",
    "tie_prueba = tie_prueba.merge(tie_2, on = 'follower_id', how = 'left')\n",
    "tie_prueba = tie_prueba.merge(tie_3, on = 'follower_id', how = 'left')\n",
    "tie_prueba = tie_prueba.merge(tie_4, on = 'follower_id', how = 'left')\n",
    "tie_prueba['batch_id'] = 'p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a492d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:21<00:00, 50.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(0, 4)):\n",
    "    tie1 = pd.read_parquet(f'{path_batches}ties_batch1_batch2_{i}.parquet').reset_index(drop =True)\n",
    "    tie2 = tie_prueba[[col for col in tie1.columns]].reset_index(drop=True)\n",
    "    \n",
    "    tie = pd.concat([tie1, tie2]).reset_index(drop = True)\n",
    "    tie.to_parquet(f'{path_batches}ties_batch1_batch2_p_{i}.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373d2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
